apiVersion: batch/v1
kind: Job
metadata:
  name: spark-dlf-runner
  labels:
    app: spark-dlf-v-runner
spec:
  #  manualSelector: true
  #  selector:
  #    matchLabels:
  #      sparkjob: belongsToDLF 
  template:
  #    metadata:
  #      labels:
  #        sparkjob: belongsToDLF 
    spec:
      restartPolicy: Never
      serviceAccountName: spark-dlf
      imagePullSecrets:
       - name: evolve-reg
      containers:
        - name: spark-tpcds1g
          image: 172.9.0.240:5000/dlf/tpcds-perf-test:latest 
          imagePullPolicy: Always
          args:
            - /opt/spark/bin/spark-submit
            - --master
            - k8s://https://$(KUBERNETES_PORT_443_TCP_ADDR):$(KUBERNETES_PORT_443_TCP_PORT)
            - --deploy-mode
            - cluster
            - --conf
            - spark.kubernetes.container.image=172.9.0.240:5000/dlf/tpcds-perf-test:latest
            - --conf
            - spark.kubernetes.container.image.pullPolicy=Always
            - --conf
            - spark.kubernetes.container.image.pullSecrets=evolve-reg
            - --conf
            - spark.kubernetes.namespace=dlf
            - --conf
            - spark.kubernetes.authenticate.driver.serviceAccountName=spark-dlf
            - --conf
            - spark.kubernetes.driver.pod.name=spark-dlf-driver
            - --conf
            - spark.driver.host=spark-dlf-svc.default.svc.cluster.local
            - --conf
            - spark.driver.port=20020
            - --conf
            - spark.driver.cores=4 
            - --conf 
            - spark.driver.memory=16g
            - --conf
            - spark.jars.ivy=/tmp/.ivy
            - --conf
            - spark.kubernetes.driver.podTemplateFile=/opt/spark/tpc-ds-performance-test/podtemplate.yaml
              #            - --conf
              #            - spark.kubernetes.driver.label.sparkjob=belongsToDLF
            - --conf
            - spark.kubernetes.driver.label.dataset.0.id=tpcds100g-nfs
            - --conf
            - spark.kubernetes.driver.label.dataset.0.useas=mount
            - --conf
            - spark.driver.maxResultSize=4g
            - --conf 
            - spark.executor.instances=8 
            - --conf
            - spark.executor.cores=4 
            - --conf 
            - spark.executor.memory=16g
            - --conf
            - spark.kubernetes.executor.podTemplateFile=/opt/spark/tpc-ds-performance-test/podtemplate.yaml
            - --conf
            - spark.kubernetes.executor.label.dataset.0.id=tpcds100g-nfs
            - --conf
            - spark.kubernetes.executor.label.dataset.0.useas=mount
            - --class
            - SparkRunner
            - local:///opt/spark/tpc-ds-benchmark-perf_2.12-0.1.jar 
            - "/mnt/datasets/tpcds100g-nfs" 
            - "TPDCS100G"
            - "3"
